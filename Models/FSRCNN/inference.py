from FSRCNN import *
import sys
import time
import torch
# import torchinfo
import numpy as np
from tqdm import tqdm
from PIL import Image
import torch.nn as nn
import torch.optim as optim
from matplotlib import pyplot as plt
# from torch.optim.lr_scheduler import StepLR
import torchvision.transforms as transforms
from low_hi_res_dataset import SR_image_dataset
from low_hi_res_dataset import SR_tensor_dataset
from torch.utils.tensorboard import SummaryWriter

from torch.nn import functional as F

NUM_EPOCHS = 100
BATCH_SIZE = 16
LEARN_RATE = 0.0005
COLOR_SPACE = 'rgb'

# Define the RGB to YUV conversion matrix and its inverse (YUV to RGB)
rgb_to_yuv = torch.tensor([[ 0.299,  0.587,  0.114],
                           [-0.14713, -0.28886,  0.436],
                           [ 0.615,  -0.51499, -0.10001]])

yuv_to_rgb = torch.inverse(rgb_to_yuv)

def yuv_to_rgb_batch(yuv_batch):
    # yuv_batch: (N, 3, H, W)
    # Step 1: Permute to (N, H, W, 3) for matrix multiplication
    yuv_batch = yuv_batch.permute(0, 2, 3, 1)  # Shape (N, H, W, 3)
    
    # Step 2: Apply YUV to RGB conversion
    rgb_batch = torch.matmul(yuv_batch, yuv_to_rgb.T)  # Shape (N, H, W, 3)
    
    # Step 3: Permute back to (N, 3, H, W)
    return rgb_batch.permute(0, 3, 1, 2)

def tensor_to_image(tensor:torch.tensor) -> Image:
    return transforms.ToPILImage()(tensor)

def plot_images(low_res, inference, truths, title:str=None):
    """
    Plots low resolution, upscaled, and ground truth images in a 3x3 grid. If title is a string, save the fig,
    otherwise show.
    Args:
        low_res (torch.Tensor): Batch of low resolution images.
        inference (torch.Tensor): Batch of upscaled images generated by the model.
        truths (torch.Tensor): Batch of ground truth high resolution images.
        title (str): Title for the plot. If provided, the plot will be saved with this title as the filename. If None, the plot will be displayed.
    Returns:
        None
    
    """
    
    low_res = low_res.cpu()
    inference = inference.cpu()
    truths = truths.cpu()
    
    if(COLOR_SPACE == 'yuv'):
        low_res = yuv_to_rgb_batch(low_res)
        inference = yuv_to_rgb_batch(inference)
        truths = yuv_to_rgb_batch(truths)

    fig, axs = plt.subplots(3, 3, figsize=(8, 8))
    for i in range(3):
        axs[0, i].imshow(tensor_to_image(low_res[i]), cmap='gray')
        axs[0, i].axis('off')
        axs[0, i].set_title('Low Res')
        
        axs[1, i].imshow(tensor_to_image(inference[i]))
        axs[1, i].axis('off')
        axs[1, i].set_title('Upscaled')
        
        axs[2, i].imshow(tensor_to_image(truths[i]))
        axs[2, i].axis('off')
        axs[2, i].set_title('Truth')
    plt.tight_layout()
    if(title is not None):
        plt.savefig(title)
    else:
        plt.show()
    plt.close()


def model_dataloader_inference(model, dataloader, device, criterion, optimizer):
    """
    Run the forward pass of model on all samples in dataloader with criterion loss. If optimizer is set to None,
    this function will NOT perform gradient updates or optimizations.
    Args:
        model(nn.Module): The neural network model
        dataloader(torch.utils.data.DataLoader): PyTorch dataloader 
        criterion(): Loss criterion (e.g. MSE loss)
        optimizer(torch.optim): Optimizer for NN
    """
    running_loss = 0.0
    for batch in dataloader:
        low_res, hi_res_truth = batch
        
        # print(f"INFO [model_dataloader_inference()] high_res shape: {hi_res_truth.shape}")
        # print(f"INFO [model_dataloader_inference()] low_res  shape: {low_res.shape}")
        
        low_res = low_res.to(device)
        hi_res_truth = hi_res_truth.to(device)
        
        optimizer.zero_grad()
        
        inference = model(low_res)
        
        # print(f"INFO [model_dataloader_inference()] inference shape: {inference.shape}")
        
        loss = criterion(inference, hi_res_truth)
        
        if(optimizer is not None):
            loss.backward()
            optimizer.step()
        
        running_loss += loss.item()
        # print(f"INFO LOSS ITEM: {loss.item() / len(batch)}")
    loss = running_loss / float(len(dataloader.dataset))
    return loss

def sec_to_human(seconds):
    """Return a number of seconds to hours, minutes, and seconds"""
    seconds = seconds % (24 * 3600)
    hours = seconds // 3600
    seconds %= 3600
    minutes = seconds // 60
    seconds %= 60
    return "%d:%02d:%02d" % (hours, minutes, seconds)

def normalize_tensor_image(rgb_tensor):
    """
    Expects rgb_tensor to be of shape (C, H, W)
    """
    
    # rgb_tensor = rgb_tensor.permute(2, 1, 0) # From (C,H,W) to (H,W,C)
    rgb_min = rgb_tensor.min()
    rgb_max = rgb_tensor.max()

    # For every pixel
    # for i in range(len(rgb_tensor)):
    #     for j in range(len(rgb_tensor[0])):
    #         largest = torch.max(rgb_tensor[i,j])
    #         smallest = torch.min(rgb_tensor[i,j])
    #         if(largest > 1.0 or smallest < 0):
                # rgb_tensor[i,j] -= smallest
                # rgb_tensor[i,j] /= (largest - smallest)
                # print(f"HAHAH I FOUND ONE:", rgb_tensor[i,j])
                # rgb_tensor[i,j] /= largest
                # rgb_tensor[i,j] = (rgb_tensor[i,j] - rgb_min) / (rgb_max - rgb_min)
    # rgb_tensor = rgb_tensor.permute(2, 1, 0) # From (H,W,C) to (C,H,W)
    
    rgb_tensor = (rgb_tensor - rgb_min) / (rgb_max - rgb_min)
                
    return rgb_tensor


def plot_inference_times():
    inference = None
    truths = None
    
    batch_sizes = np.arange(2000) + 2
    inference_times = np.zeros(2000)
    
    low_res_tensors = torch.load('../data/data/low_res_tensors.pt', weights_only=True)
    
    n_avg = 100
    
    model.eval()
    for i in range(len(batch_sizes)):
        batch = low_res_tensors[0:batch_sizes[i]]
        
        batch = batch.to(device)
        
        for n in range(n_avg):
            t_prior = time.time()
            inference = model(batch)
            t_inference = time.time() - t_prior
            
            inference_times[i] += t_inference
        inference_times[i] /= n_avg
        
        print(f"INFO [inference.py] Batch size: {batch_sizes[i]:>5} Inference Time: {inference_times[i]:.6f}", flush=True)
        
        # loss = criterion(inference, hi_res_truth)

    plt.plot(batch_sizes, inference_times)
    plt.savefig('./inference_times.png')
    
def text_to_featuremaps(path:str, num_feature_maps)->np.ndarray:
    """
    Reads a text file containing feature maps and returns them as a numpy array.
    Args:
        path (str): Path to the text file containing the feature maps.
        num_feature_maps (int): Number of feature maps to read from the file.
    Returns:
        np.ndarray: Feature maps as a numpy array of shape (44, 28, 28)
    """
    feature_maps = []
    
    with open(path, "r") as file:
        lines = file.readlines()
    
    # Find the start of the feature maps
    start_idx = None
    for i, line in enumerate(lines):
        if "INFO [conv2d] Feature map 0:" in line:
            start_idx = i + 1  # Start from the next line
            break

    if start_idx is None:
        raise ValueError("Feature map start not found in the file.")
    
    # Read 44 feature maps, each consisting of 28x28 lines
    feature_map_size = 28 * 28

    for i in range(num_feature_maps):
        # Skip the first two lines (header and empty line)
        start = start_idx + i * (feature_map_size + 2)
        end = start + feature_map_size
        feature_map = np.array([float(x.strip()) for x in lines[start:end]]).reshape(28, 28)
        feature_maps.append(feature_map)

    return np.array(feature_maps)  # Shape: (num_feature_maps, 28, 28)


def compare_results(dut_produced:np.ndarray, ideal:np.ndarray):
    """
    TODO: Rewrite to use numpy functions instead of for loops
    """
    worst_err = 0.0
    total_error = 0.0
    for map_idx in range(dut_produced.shape[0]):
        for row in range(dut_produced.shape[1]):
            for col in range(dut_produced.shape[2]):
                
                error = abs(dut_produced[map_idx][row][col] - ideal[map_idx][row][col])
                total_error += error
                
                if(error > worst_err):
                    worst_err = error
                
    avg_error = total_error / (dut_produced.shape[0] * dut_produced.shape[1] * dut_produced.shape[2])
    # print(f"INFO [inference.py] Total error: {total_error:.6f}")
    # print(f"INFO [inference.py] Average error per pixel: {avg_error:.6f} ({(avg_error*255):.6f})")
    
    return total_error, avg_error, worst_err
    

def compare_5x5_conv(ideal_inference:np.ndarray):
    # Read the simulation log results
    one_shot_conv = text_to_featuremaps('../../HLS/build/conv2d_proj/solution1/csim/report/conv2d_1shot.log', 44)
    pe_loop_produced = text_to_featuremaps('../../HLS/build/conv2d_proj/solution1/csim/report/conv2d_not_even.log', 44)
    python_generated = text_to_featuremaps('../../HLS/build/conv2d_proj/solution1/csim/report/conv2d_python_5x5.log', 44)
    
    # 1 shot: Somewhat ideal case
    total_err, avg_err, worst_err = compare_results(one_shot_conv, ideal_inference)    
    print("1-shot:")
    print(f'INFO [inference.py] Total error from 1 shot:     {total_err:0.6f}')
    print(f'INFO [inference.py] Average error from 1 shot:   {avg_err:0.6f} --> {avg_err * 255:0.6f}')
    print(f'INFO [inference.py] Worst error from 1 shot:     {worst_err:0.6f} --> {worst_err * 255:0.6f}')
    
    total_err, avg_err, worst_err = compare_results(python_generated, ideal_inference)    
    print("PE Loops:")
    print(f'INFO [inference.py] Total error from PE loops:   {total_err:0.6f}')
    print(f'INFO [inference.py] Average error from PE loops: {avg_err:0.6f} --> {avg_err * 255:0.6f}')
    print(f'INFO [inference.py] Worst error from PE loops:   {worst_err:0.6f} --> {worst_err * 255:0.6f}')
    
    print("INFO [inference.py] Max difference between PE loop and python generated: ")
    # print(np.max(np.abs(pe_loop_produced - python_generated)))
    
    diffs_pe = np.abs(python_generated - ideal_inference).flatten() * 255
    diffs_1shot = np.abs(one_shot_conv - ideal_inference).flatten() * 255

    # Plot histograms
    plt.hist(diffs_pe, bins=50, alpha=0.5, label="Python Generated", edgecolor='black', color='cyan')
    plt.hist(diffs_1shot, bins=50, alpha=0.5, label="1-Shot", edgecolor='black', color='red')

    # Labels and title
    plt.xlabel("Absolute Difference")
    plt.ylabel("Frequency")
    plt.title("Comparison of Absolute Differences - Extraction Layer")
    plt.legend()  # Show the legend
    plt.grid(True)

    # Show plot
    plt.show()
    
if __name__ == '__main__':
    tstart = time.time()
    print(f"INFO [inference.py] Starting script at {tstart}")
    
    # Set up device, model
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f'INFO [inference.py] Using device: {device} [torch version: {torch.__version__}]')
    print(f'INFO [inference.py] Python version: {sys.version_info[0]}.{sys.version_info[1]}.{sys.version_info[2]}')
    model = FSRCNN(upscale_factor=2, color_space=COLOR_SPACE).to(device)
    model.load_state_dict(torch.load('./saved_weights/example_vitis_hls_weights_44.pth', weights_only=True))
    
    # print_model_summary(model, 1, 3, 32, 32)
    # exit()
    
    criterion = nn.MSELoss()
    
    # Get dataset
    seed = 50  # Set the seed for reproducibility
    torch.manual_seed(seed)
    # print("INFO [inference.py] Loading Tensor pair dataset")
    # full_dataset = SR_tensor_dataset(high_res_tensors_path='../data/data/high_res_tensors_10k.pt', low_res_tensors_path='../data/data/low_res_tensors_10k.pt')
    
    # Create train and test datasets. Set small train set for faster training

    # train_dataset, valid_dataset, test_dataset = \
    #         torch.utils.data.random_split(full_dataset, [0.85, 0.10, 0.05], generator=torch.Generator())
    # num_train_samples = len(train_dataset)
    # print(f'INFO [inference.py] Total num data samples:    {len(full_dataset)}')
    # print(f'INFO [inference.py] Num of training samples:   {num_train_samples}')
    # print(f'INFO [inference.py] Num of validation samples: {len(valid_dataset)}')
    # print(f'INFO [inference.py] Num of test samples:       {len(test_dataset)}')
    
    # Get Dataloader
    # train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    # valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)
    # test_dataloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=True)
    # print(f'INFO [inference.py] Num training batches: {len(train_dataloader)}')

    low_res_coin = torch.from_numpy(np.load('../comparisons/images/image_coin_tile.npy'))
    low_res_coin = low_res_coin.float()
    
    # Change shape from (28, 28, 3) â†’ (1, 3, 28, 28) for pytorch
    low_res_coin = low_res_coin.permute(2, 0, 1).unsqueeze(0) / 256.
    # inference = model.feature_extraction(low_res_coin.to(device)).squeeze(0).cpu().detach().numpy()
    inference = model.feature_extraction(low_res_coin.to(device))
    # inference = model.shrink(inference)
    # inference = model.map(inference)
    # inference = model.expand(inference)
    
    inference = inference.squeeze(0).cpu().detach().numpy()
    print(inference[0,0])
    # compare_5x5_conv(inference)
    # exit()
    
    last_conv = text_to_featuremaps('../../HLS/build/conv2d_proj/solution1/csim/report/conv2d_top_csim.log', 44)
    errors = np.abs(inference - last_conv).flatten()
    
    pct_errors = np.abs((inference - last_conv) / inference).flatten() * 100
    cutoff = 30
    horrendously_wrong = pct_errors[pct_errors >= cutoff]
    pct_errors = pct_errors[pct_errors < cutoff]
    print(f"Percent of values < 5% error: {len(pct_errors[pct_errors < 5]) / len(pct_errors) * 100: 0.2f}")
    avg = np.mean(pct_errors)
    worst = np.max(pct_errors)
    print(f"Average error: {avg:9.6f}")
    print(f"Worst error:   {worst:9.6f}")
    
    fig, (ax1, ax2) = plt.subplots(2, 1, sharey=True, figsize=(8, 5))

    # First histogram (percent error)
    ax1.hist(pct_errors, bins=50, alpha=0.5, label="Percent Error", edgecolor='black', color='cyan')
    ax1.set_xlabel("Percent Error")
    ax1.set_ylabel("Frequency")
    ax1.set_title("Histogram of Percent Error")
    ax1.legend()
    ax1.grid(True)

    # Second histogram (absolute errors)
    ax2.hist(errors, bins=50, alpha=0.5, label="Absolute Error", edgecolor='black', color='red')
    ax2.set_xlabel("Absolute Error")
    ax2.set_ylabel("Frequency")
    ax2.set_title("Histogram of Absolute Error")
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    plt.show()