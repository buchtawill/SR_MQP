
@misc{johnson_version_2014,
	title = {Version control for {Vivado} projects},
	url = {https://www.fpgadeveloper.com/2014/08/version-control-for-vivado-projects.html/},
	abstract = {Vivado generates a whole bunch of files when you create a project, and it’s not very clear on which are source files and which are generated files. The best approach is to consider them all to be generated files and to put none of them in version control. Instead, create a folder stucture for your sources that makes sense to you and use Tcl scripts to build the project and import the sources.},
	language = {en},
	urldate = {2025-04-18},
	journal = {FPGA Developer},
	author = {Johnson, Jeff},
	month = aug,
	year = {2014},
}

@misc{knitter_vivado_2023,
	title = {Vivado, {Vitis}, \& {PetaLinux} 2023.1 {Install} on {Ubuntu} 22.04},
	url = {https://www.hackster.io/whitney-knitter/vivado-vitis-petalinux-2023-1-install-on-ubuntu-22-04-ab28da},
	abstract = {A quick write-up guide on the installation process of AMD's FPGA development tools on Ubuntu 22.04 LTS. By Whitney Knitter.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Hackster.io},
	author = {Knitter, Whitney},
	month = aug,
	year = {2023},
}

@misc{dumoulin_guide_2016,
	title = {A guide to convolution arithmetic for deep learning},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1603.07285},
	doi = {10.48550/ARXIV.1603.07285},
	abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Dumoulin, Vincent and Visin, Francesco},
	year = {2016},
	keywords = {FOS: Computer and information sciences, Machine Learning (cs.LG), Machine Learning (stat.ML), Neural and Evolutionary Computing (cs.NE)},
}

@misc{ratan_what_2020,
	title = {What is the {Convolutional} {Neural} {Network} {Architecture}?},
	url = {https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/},
	abstract = {Learn the Convolutional Neural Networks (CNN) and build a foundational architecture for image recognition and object detection projects.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Analytics Vidhya},
	author = {Ratan, Phani},
	month = oct,
	year = {2020},
}

@misc{amd_plnx_ug,
	title = {{AMD} {Technical} {Information} {Portal}},
	url = {https://docs.amd.com/r/2023.1-English/ug1144-petalinux-tools-reference-guide/Overview},
	urldate = {2025-04-22},
}

@misc{ratan_what_2020-1,
	title = {What is the {Convolutional} {Neural} {Network} {Architecture}?},
	url = {https://www.analyticsvidhya.com/blog/2020/10/what-is-the-convolutional-neural-network-architecture/},
	abstract = {Learn the Convolutional Neural Networks (CNN) and build a foundational architecture for image recognition and object detection projects.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Analytics Vidhya},
	author = {Ratan, Phani},
	month = oct,
	year = {2020},
}

@misc{newren_newrengit-filter-repo_2025,
	title = {newren/git-filter-repo},
	url = {https://github.com/newren/git-filter-repo},
	abstract = {Quickly rewrite git repository history (filter-branch replacement)},
	urldate = {2025-04-22},
	author = {Newren, Elijah},
	month = apr,
	year = {2025},
	note = {original-date: 2018-08-21T15:40:09Z},
}

@misc{zewe_explained_2025,
	title = {Explained: {Generative} {AI}’s environmental impact},
	shorttitle = {Explained},
	url = {https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117},
	abstract = {MIT News explores the environmental and sustainability implications of generative AI technologies and applications.},
	language = {en},
	urldate = {2025-04-22},
	journal = {MIT News},
	author = {Zewe, Adam},
	month = jan,
	year = {2025},
}

@misc{aldridge_understanding_2023,
	title = {Understanding the {Monte} {Carlo} {Analysis} in {Project} {Management}},
	url = {https://projectmanagementacademy.net/resources/blog/understanding-the-monte-carlo-analysis-in-project-management/},
	abstract = {The Monte Carlo method is a mathematical technique and general computational approach used to estimate the behavior of complex systems or processes.},
	language = {en-US},
	urldate = {2025-04-22},
	journal = {Project Management Academy Resources},
	author = {Aldridge, Erin},
	month = jun,
	year = {2023},
}

@misc{szcezepanek_bilinear_2024,
	title = {Bilinear {Interpolation} {Calculator}},
	url = {https://www.omnicalculator.com/math/bilinear-interpolation},
	abstract = {The bilinear interpolation calculator helps you estimate the value of an unknown function based on the method of bilinear interpolation.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Omni Calculator},
	author = {Szcezepanek, Anna},
	month = jun,
	year = {2024},
}

@article{yang_fast_2007,
	title = {A {Fast} {Algorithm} for {YCbCr} to {RGB} {Conversion}},
	volume = {53},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0098-3063, 1558-4127},
	url = {https://ieeexplore.ieee.org/document/4429242/},
	doi = {10.1109/TCE.2007.4429242},
	number = {4},
	urldate = {2025-04-22},
	journal = {IEEE Transactions on Consumer Electronics},
	author = {Yang, Yang and Yuhua, Peng and Zhaoguang, Liu},
	month = nov,
	year = {2007},
	pages = {1490--1493},
}

@misc{noauthor_amba_2021,
	title = {{AMBA} {AXI}-{Stream}},
	url = {https://developer.arm.com/documentation/ihi0051/latest/},
	urldate = {2025-04-22},
	year = {2021},
}

@misc{cadence_uvm_nodate,
	title = {{UVM} {Verification}},
	url = {https://www.cadence.com/en_US/home/explore/uvm-verification.html},
	abstract = {UVM verification is a set of standards, tools, and APIs for creating a universal way of verifying designs. Learn more about what UVM is, why it is important and UVM verification with Cadence.},
	language = {en},
	urldate = {2025-04-19},
	author = {{Cadence}},
}

@misc{siemens_uvm_nodate,
	title = {{UVM} - {Universal} {Verification} {Methodology}},
	url = {https://verificationacademy.com/topics/uvm-universal-verification-methodology/verificationacademy.com/topics/uvm-universal-verification-methodology/},
	abstract = {The Universal Verification Methodology (UVM) is a powerful framework for designing and verifying complex digital systems, offering significant benefits in terms of reusable and scalable testbenches. UVM promotes reusability by providing a standardized methodology for creating modular, configurable verification components. This modular approach allows engineers to develop testbenches using reusable building blocks, reducing redundancy and saving time.Furthermore, UVM enhances scalability, enabling easy adaptation to changing project requirements. As designs evolve, UVM\&\#x27;s hierarchical and flexible architecture simplifies the addition or modification of testbench components, ensuring efficient and maintainable verification environments. Overall, UVM streamlines the verification process, promoting productivity and ensuring robust, adaptable testbenches.},
	language = {en-us},
	urldate = {2025-04-22},
	journal = {Verification Academy},
	author = {{Siemens}},
}

@misc{siemens_pipelining_nodate,
	title = {Pipelining},
	url = {https://hls.academy/topics/pipelining/hls.academy/topics/pipelining/},
	abstract = {Pipelining drives throughput and is used with loop unrolling to drive overall throughput. Initiation Intervals greater than one can enhance sharing.},
	language = {en-us},
	urldate = {2025-04-22},
	journal = {HLS Academy},
	author = {{Siemens}},
}

@misc{intel_intel_2019,
	title = {Intel® {High} {Level} {Synthesis} {Compiler} {Standard} {Edition}: {Reference} {Manual}},
	publisher = {Intel},
	author = {{Intel}},
	month = dec,
	year = {2019},
}

@misc{amd_vitis_nodate,
	title = {Vitis {High}-{Level} {Synthesis} {User} {Guide}},
	url = {https://docs.amd.com/r/2024.2-English/ug1399-vitis-hls/syn.directive.unroll},
	urldate = {2025-04-22},
	journal = {AMD Technical Information Portal},
	author = {{AMD}},
}

@inproceedings{bailey_advantages_2015,
	address = {Seville Spain},
	title = {The advantages and limitations of high level synthesis for {FPGA} based image processing},
	isbn = {9781450336819},
	url = {https://dl.acm.org/doi/10.1145/2789116.2789145},
	doi = {10.1145/2789116.2789145},
	language = {en},
	urldate = {2025-04-22},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Distributed} {Smart} {Cameras}},
	publisher = {ACM},
	author = {Bailey, Donald G.},
	month = sep,
	year = {2015},
	pages = {134--139},
}

@inproceedings{sarg_efficient_2021,
	address = {New Cairo City, Egypt},
	title = {Efficient {HLS} {Implementation} for {Convolutional} {Neural} {Networks} {Accelerator} on an {SoC}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {9781665408394},
	url = {https://ieeexplore.ieee.org/document/9664920/},
	doi = {10.1109/ICM52667.2021.9664920},
	urldate = {2025-04-22},
	booktitle = {2021 {International} {Conference} on {Microelectronics} ({ICM})},
	publisher = {IEEE},
	author = {Sarg, Muhammad and Khalil, Ahmed H. and Mostafa, Hassan},
	month = dec,
	year = {2021},
	pages = {1--4},
}

@inproceedings{zhang_optimizing_2015,
	address = {Monterey California USA},
	title = {Optimizing {FPGA}-based {Accelerator} {Design} for {Deep} {Convolutional} {Neural} {Networks}},
	isbn = {9781450333153},
	url = {https://dl.acm.org/doi/10.1145/2684746.2689060},
	doi = {10.1145/2684746.2689060},
	language = {en},
	urldate = {2025-04-22},
	booktitle = {Proceedings of the 2015 {ACM}/{SIGDA} {International} {Symposium} on {Field}-{Programmable} {Gate} {Arrays}},
	publisher = {ACM},
	author = {Zhang, Chen and Li, Peng and Sun, Guangyu and Guan, Yijin and Xiao, Bingjun and Cong, Jason},
	month = feb,
	year = {2015},
	pages = {161--170},
}

@misc{wei_understand_2020,
	title = {Understand {Transposed} {Convolutions}},
	url = {https://medium.com/data-science/understand-transposed-convolutions-and-build-your-own-transposed-convolution-layer-from-scratch-4f5d97b2967},
	abstract = {Get to know the concepts of transposed convolutions and build your own transposed convolutional layers from scratch},
	language = {en},
	urldate = {2025-04-22},
	journal = {TDS Archive},
	author = {Wei, Kuan},
	month = sep,
	year = {2020},
}

@misc{he_delving_2015,
	title = {Delving {Deep} into {Rectifiers}: {Surpassing} {Human}-{Level} {Performance} on {ImageNet} {Classification}},
	shorttitle = {Delving {Deep} into {Rectifiers}},
	url = {http://arxiv.org/abs/1502.01852},
	doi = {10.48550/arXiv.1502.01852},
	abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = feb,
	year = {2015},
	note = {arXiv:1502.01852},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{machine_learning_in_plain_english_convolutional_2023,
	title = {Convolutional {Neural} {Network} — {Lesson} 9: {Activation} {Functions} in {CNNs}},
	shorttitle = {Convolutional {Neural} {Network} — {Lesson} 9},
	url = {https://medium.com/@nerdjock/convolutional-neural-network-lesson-9-activation-functions-in-cnns-57def9c6e759},
	abstract = {The Need for Non-Linearity: ReLU, Leaky ReLU, etc.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Medium},
	author = {{Machine Learning in Plain English}},
	month = jun,
	year = {2023},
}

@misc{unzueta_fully_nodate,
	title = {Fully {Connected} {Layer} vs. {Convolutional} {Layer}: {Explained}},
	shorttitle = {Fully {Connected} {Layer} vs. {Convolutional} {Layer}},
	url = {https://builtin.com/machine-learning/fully-connected-layer},
	abstract = {A fully connected layer is a neural network layer where each input node is connected to each output node. In a convolutional layer, not all nodes are connected. Here’s what you need to know.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Built In},
	author = {Unzueta, Diego},
}

@misc{guo_survey_2018,
	title = {A {Survey} of {FPGA}-{Based} {Neural} {Network} {Accelerator}},
	url = {http://arxiv.org/abs/1712.08934},
	doi = {10.48550/arXiv.1712.08934},
	abstract = {Recent researches on neural network have shown significant advantage in machine learning over traditional algorithms based on handcrafted features and models. Neural network is now widely adopted in regions like image, speech and video recognition. But the high computation and storage complexity of neural network inference poses great difficulty on its application. CPU platforms are hard to offer enough computation capacity. GPU platforms are the first choice for neural network process because of its high computation capacity and easy to use development frameworks. On the other hand, FPGA-based neural network inference accelerator is becoming a research topic. With specifically designed hardware, FPGA is the next possible solution to surpass GPU in speed and energy efficiency. Various FPGA-based accelerator designs have been proposed with software and hardware optimization techniques to achieve high speed and energy efficiency. In this paper, we give an overview of previous work on neural network inference accelerators based on FPGA and summarize the main techniques used. An investigation from software to hardware, from circuit level to system level is carried out to complete analysis of FPGA-based neural network inference accelerator design and serves as a guide to future work.},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Guo, Kaiyuan and Zeng, Shulin and Yu, Jincheng and Wang, Yu and Yang, Huazhong},
	month = dec,
	year = {2018},
	note = {arXiv:1712.08934},
	keywords = {Computer Science - Hardware Architecture},
}

@inproceedings{ma_scalable_2016,
	address = {Lausanne, Switzerland},
	title = {Scalable and modularized {RTL} compilation of {Convolutional} {Neural} {Networks} onto {FPGA}},
	isbn = {9782839918442},
	url = {http://ieeexplore.ieee.org/document/7577356/},
	doi = {10.1109/FPL.2016.7577356},
	urldate = {2025-04-22},
	booktitle = {2016 26th {International} {Conference} on {Field} {Programmable} {Logic} and {Applications} ({FPL})},
	publisher = {IEEE},
	author = {Ma, Yufei and Suda, Naveen and {Cao, Yu} and Seo, Jae-sun and Vrudhula, Sarma},
	month = aug,
	year = {2016},
	pages = {1--8},
}

@misc{pendhari_connected_2024,
	title = {Connected {Layer} vs {Fully} {Connected} {Layer}},
	url = {https://medium.com/@sarahpendhari/connected-layer-vs-fully-connected-layer-32b4cbb29824},
	abstract = {The Layer Showdown You Didn’t Know You Needed!},
	language = {en},
	urldate = {2025-04-22},
	journal = {Medium},
	author = {Pendhari, Sarah},
	month = dec,
	year = {2024},
}

@article{giachetti_real_time_2011,
	title = {Real-{Time} {Artifact}-{Free} {Image} {Upscaling}},
	volume = {20},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1057-7149, 1941-0042},
	url = {http://ieeexplore.ieee.org/document/5741850/},
	doi = {10.1109/TIP.2011.2136352},
	number = {10},
	urldate = {2025-04-22},
	journal = {IEEE Transactions on Image Processing},
	author = {Giachetti, Andrea and Asuni, Nicola},
	month = oct,
	year = {2011},
	pages = {2760--2768},
}

@misc{amanrao_image_2023,
	title = {Image {Upscaling} {Using} {Bicubic} {Interpolation}},
	url = {https://medium.com/@amanrao032/image-upscaling-using-bicubic-interpolation-ddb37295df0},
	abstract = {Image Upscaling is the process by which we increase the resolution of the image while minimizing the loss in image quality that occurs due…},
	language = {en},
	urldate = {2025-04-22},
	journal = {Medium},
	author = {{Amanrao}},
	month = sep,
	year = {2023},
}

@misc{noauthor_zoom_2012,
	title = {Zoom {Images} : {Nearest} {Neighbour} \& {Bilinear} {Interpolation}},
	url = {https://tjeyamy.blogspot.com/2012/01/zoom-images-nearest-neighbour-bilinear.html},
	urldate = {2025-04-22},
	journal = {JeyaTech},
	month = jan,
	year = {2012},
	keywords = {Algorithms, Image Processing, MATLAB},
}

@misc{taranvh_nearest_2023,
	title = {Nearest {Neighbor} {Scaling}},
	url = {https://community.adobe.com/t5/premiere-pro-ideas/nearest-neighbor-scaling-sampling-simple-and-vital/idi-p/13515843},
	abstract = {After Effects allows you to use Bicubic, bilinear, and nearest neighbor ("draft") for scaling. (Also known as "sampling" or "interpolation.")  Premiere should absolutely have the option for the Motion effect to use Nearest Neighbor. (It would still be bicubic by default, as it is now.)  This is very...},
	language = {en},
	urldate = {2025-04-22},
	journal = {Adobe Community},
	author = {{TaranVH}},
	month = jan,
	year = {2023},
}

@article{patel_review_2013,
	title = {A {Review} on {Different} {Image} {Interpolation} {Techniques} for {Image} {Enhancement}},
	volume = {3},
	issn = {2250-2459},
	url = {https://d1wqtxts1xzle7.cloudfront.net/58086182/2_A_Review_on_Different_Image_Interpolation_Techniques_for_Image_Enhancement-libre.pdf?1546191972=&response-content-disposition=inline%3B+filename%3DA_Review_on_Different_Image_Interpolatio.pdf&Expires=1744694077&Signature=X2y2-N7LoR3DWLUOxbyldmmFNBwUmMUHWVr3Mgewn7nK~ZOYD6lxOjVqFATwsKJK3PzoJ0BYiXx4G7DiYC7D8tbW5gf9uV9wBkk9ZQrLEyyfQjEQRGj9wUPaXvS~9qzyUvyfM-Xm-cP16359toD5dM~BWtRwx6qp5Td3xJkpQ-wF~n36s2e8oWd0P~KveCaZouY6jpM00I40J9LNimd5PneTvbHn9Vt6qlQonJfUBrL1tezBKbBUeJ9pQgz5q1maatyaMFBv0VIBTTZoTw0HYAZdheAELfYp9LIN1VpAaBdUK6BDl50Uu~gDa8o4o5X8R28dkguWeuW9uiheeteP8A__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA},
	number = {12},
	journal = {International Journal of Emerging Technology and Advanced Engineering},
	author = {Patel, Vaishali and Mistree, Kinjal},
	month = dec,
	year = {2013},
}

@article{fadnavis_image_2014,
	title = {Image {Interpolation} {Techniques} in {Digital} {Image} {Processing}: {An} {Overview}},
	volume = {4`},
	issn = {2248-9622},
	url = {https://www.researchgate.net/profile/Shreyas-Fadnavis/publication/301889708_Image_Interpolation_Techniques_in_Digital_Image_Processing_An_Overview/links/5abcee20a6fdcccda656f974/Image-Interpolation-Techniques-in-Digital-Image-Processing-An-Overview.pdf},
	number = {10},
	journal = {International Journal of Engineering Research and Applications},
	author = {Fadnavis, Shreyas},
	month = oct,
	year = {2014},
	pages = {70--73},
}

@misc{pai_understanding_2024,
	title = {Understanding {RGB}, {YCbCr} and {Lab} {Color} {Spaces}},
	url = {https://medium.com/@weichenpai/understanding-rgb-ycbcr-and-lab-color-spaces-f9c4a5fe485a},
	abstract = {Color spaces are essential in digital imaging and computer graphics, as they provide a means of representing colors in a standardized way.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Medium},
	author = {Pai, Nick},
	year = {2024},
}

@misc{noauthor_introduction_nodate,
	title = {Introduction to {Color} {Spaces} in {Video}},
	url = {https://video.matrox.com/en/media/guides-articles/introduction-color-spaces-video},
	abstract = {This guide aims to explain the representation of color in a video setting while outlining the differences between common color models.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Matrox Video},
}

@misc{yuyv_rgb_img,
	title = {What are {RGB} and {YUV} color spaces? {I} {DEXON} {Blog}},
	shorttitle = {What are {RGB} and {YUV} color spaces?},
	url = {https://dexonsystems.com/blog/rgb-yuv-color-spaces},
	abstract = {Color spaces can be tricky things to navigate but are essential for producing vibrant and attractive images and videos that pop with color.},
	language = {en-US},
	urldate = {2025-04-22},
	journal = {DEXON Systems- Visual Quality Innovation},
	month = apr,
	year = {2022},
}

@inproceedings{li_convolutional_2015,
	address = {Boston},
	title = {A {Convolutional} {Neural} {Network} {Cascade} for {Face} {Detection}},
	author = {Li, Haoxiang and Lin, Zhe and Shen, Xiaohui and Brandt, Jonathan and Hua, Gang},
	year = {2015},
	pages = {5325--5334},
}

@article{naranjo-torres_review_2020,
	title = {A {Review} of {Convolutional} {Neural} {Network} {Applied} to {Fruit} {Image} {Processing}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/10/10/3443},
	doi = {10.3390/app10103443},
	abstract = {Agriculture has always been an important economic and social sector for humans. Fruit production is especially essential, with a great demand from all households. Therefore, the use of innovative technologies is of vital importance for the agri-food sector. Currently artificial intelligence is one very important technological tool widely used in modern society. Particularly, Deep Learning (DL) has several applications due to its ability to learn robust representations from images. Convolutional Neural Networks (CNN) is the main DL architecture for image classification. Based on the great attention that CNNs have had in the last years, we present a review of the use of CNN applied to different automatic processing tasks of fruit images: classification, quality control, and detection. We observe that in the last two years (2019–2020), the use of CNN for fruit recognition has greatly increased obtaining excellent results, either by using new models or with pre-trained networks for transfer learning. It is worth noting that different types of images are used in datasets according to the task performed. Besides, this article presents the fundamentals, tools, and two examples of the use of CNNs for fruit sorting and quality control.},
	language = {en},
	number = {10},
	urldate = {2025-04-22},
	journal = {Applied Sciences},
	author = {Naranjo-Torres, José and Mora, Marco and Hernández-García, Ruber and Barrientos, Ricardo J. and Fredes, Claudio and Valenzuela, Andres},
	month = may,
	year = {2020},
	pages = {3443},
}

@article{van_ouwerkerk_image_2006,
	title = {Image super-resolution survey},
	volume = {24},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {02628856},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0262885606001089},
	doi = {10.1016/j.imavis.2006.02.026},
	language = {en},
	number = {10},
	urldate = {2025-04-22},
	journal = {Image and Vision Computing},
	author = {Van Ouwerkerk, J.D.},
	month = oct,
	year = {2006},
	pages = {1039--1052},
}

@inproceedings{he_fpga_based_2018,
	address = {Boulder, CO, USA},
	title = {{FPGA}-{Based} {Real}-{Time} {Super}-{Resolution} {System} for {Ultra} {High} {Definition} {Videos}},
	isbn = {9781538655221},
	url = {https://ieeexplore.ieee.org/document/8457651/},
	doi = {10.1109/FCCM.2018.00036},
	urldate = {2025-04-22},
	booktitle = {2018 {IEEE} 26th {Annual} {International} {Symposium} on {Field}-{Programmable} {Custom} {Computing} {Machines} ({FCCM})},
	publisher = {IEEE},
	author = {He, Zhuolun and Huang, Hanxian and Jiang, Ming and Bai, Yuanchao and Luo, Guojie},
	month = apr,
	year = {2018},
	pages = {181--188},
}

@misc{srcnn_dong_2015,
	title = {Image {Super}-{Resolution} {Using} {Deep} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1501.00092},
	doi = {10.48550/arXiv.1501.00092},
	abstract = {We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {Dong, Chao and Loy, Chen Change and He, Kaiming and Tang, Xiaoou},
	month = jul,
	year = {2015},
	note = {arXiv:1501.00092},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing},
}

@misc{retro_games,
	title = {Top of the leaderboard: the most popular retro video games from the 1980s and 1990s},
	shorttitle = {Top of the leaderboard},
	url = {https://elvtr.com/blog/top-of-the-leaderboard-the-most-popular-retro-video-games-from-the-1980s-and-1990s},
	abstract = {Game over for Mario, Pac-Man, Sonic, and Solid Snake. It’s Minesweeper and Mortal Kombat that claim victory when it comes to nostalgia for video games released in the 1980s and 1990s.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Elvtr},
	author = {{Elvtr}},
}

@misc{choi_pixel_2023,
	title = {Pixel {Perfect}: {RTX} {Video} {Super} {Resolution} {Now} {Available} for {GeForce} {RTX} 40 and 30 {Series} {GPUs}},
	shorttitle = {Pixel {Perfect}},
	url = {https://blogs.nvidia.com/blog/rtx-video-super-resolution/},
	abstract = {Learn how RTX Video Super Resolution uses AI to improve streaming video in latest Game Ready Driver for GeForce RTX 40 and 30 Series GPUs.},
	language = {en-US},
	urldate = {2025-04-22},
	journal = {NVIDIA},
	author = {Choi, Brian},
	month = feb,
	year = {2023},
}

@misc{noauthor_browser_nodate,
	title = {Browser {Display} {Statistics}},
	url = {https://www.w3schools.com/browsers/browsers_display.asp},
	abstract = {W3Schools offers free online tutorials, references and exercises in all the major languages of the web. Covering popular subjects like HTML, CSS, JavaScript, Python, SQL, Java, and many, many more.},
	language = {en-US},
	urldate = {2025-04-22},
}

@techreport{fsrcnn_dong_accelerating_2016,
	title = {Accelerating the {Super}-{Resolution} {Convolutional} {Neural} {Network}},
	url = {http://arxiv.org/abs/1608.00367},
	abstract = {As a successful deep model applied in image super-resolution (SR), the Super-Resolution Convolutional Neural Network (SRCNN) has demonstrated superior performance to the previous hand-crafted models either in speed and restoration quality. However, the high computational cost still hinders it from practical usage that demands real-time performance (24 fps). In this paper, we aim at accelerating the current SRCNN, and propose a compact hourglass-shape CNN structure for faster and better SR. We re-design the SRCNN structure mainly in three aspects. First, we introduce a deconvolution layer at the end of the network, then the mapping is learned directly from the original low-resolution image (without interpolation) to the high-resolution one. Second, we reformulate the mapping layer by shrinking the input feature dimension before mapping and expanding back afterwards. Third, we adopt smaller filter sizes but more mapping layers. The proposed model achieves a speed up of more than 40 times with even superior restoration quality. Further, we present the parameter settings that can achieve real-time performance on a generic CPU while still maintaining good performance. A corresponding transfer strategy is also proposed for fast training and testing across different upscaling factors.},
	number = {arXiv:1608.00367},
	urldate = {2025-04-22},
	institution = {arXiv},
	author = {Dong, Chao and Loy, Chen Change and Tang, Xiaoou},
	month = aug,
	year = {2016},
	note = {arXiv:1608.00367},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{noauthor_ug1399_nodate,
	title = {{UG1399}: {Vitis} {HLS} {User} {Guide}},
	url = {https://docs.amd.com/r/2023.1-English/ug1399-vitis-hls},
	urldate = {2025-04-21},
}

@article{panchbhaiyye_efficient_2021,
	title = {An {Efficient} {FIFO} {Based} {Accelerator} for {Convolutional} {Neural} {Networks}},
	volume = {93},
	issn = {1939-8018, 1939-8115},
	url = {https://link.springer.com/10.1007/s11265-020-01632-0},
	doi = {10.1007/s11265-020-01632-0},
	language = {en},
	number = {10},
	urldate = {2025-04-21},
	journal = {Journal of Signal Processing Systems},
	author = {Panchbhaiyye, Vineet and Ogunfunmi, Tokunbo},
	month = oct,
	year = {2021},
	pages = {1117--1129},
}

@misc{cspo_understanding_2023,
	title = {Understanding the {Monte} {Carlo} {Analysis} in {Project} {Management}},
	url = {https://projectmanagementacademy.net/resources/blog/understanding-the-monte-carlo-analysis-in-project-management/},
	abstract = {The Monte Carlo method is a mathematical technique and general computational approach used to estimate the behavior of complex systems or processes.},
	language = {en-US},
	urldate = {2025-04-19},
	journal = {Project Management Academy Resources},
	author = {CSPO, PMP, PMI-ACP, \&, Erin Aldridge},
	month = jun,
	year = {2023},
}

@misc{zhu_unpaired_2017,
	title = {Unpaired {Image}-to-{Image} {Translation} using {Cycle}-{Consistent} {Adversarial} {Networks}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1703.10593},
	doi = {10.48550/ARXIV.1703.10593},
	abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain \$X\$ to a target domain \$Y\$ in the absence of paired examples. Our goal is to learn a mapping \$G: X {\textbackslash}rightarrow Y\$ such that the distribution of images from \$G(X)\$ is indistinguishable from the distribution \$Y\$ using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping \$F: Y {\textbackslash}rightarrow X\$ and introduce a cycle consistency loss to push \$F(G(X)) {\textbackslash}approx X\$ (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
	urldate = {2025-04-19},
	publisher = {arXiv},
	author = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	year = {2017},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences},
}

@misc{park_contrastive_2020,
	title = {Contrastive {Learning} for {Unpaired} {Image}-to-{Image} {Translation}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2007.15651},
	doi = {10.48550/ARXIV.2007.15651},
	abstract = {In image-to-image translation, each patch in the output should reflect the content of the corresponding patch in the input, independent of domain. We propose a straightforward method for doing so -- maximizing mutual information between the two, using a framework based on contrastive learning. The method encourages two elements (corresponding patches) to map to a similar point in a learned feature space, relative to other elements (other patches) in the dataset, referred to as negatives. We explore several critical design choices for making contrastive learning effective in the image synthesis setting. Notably, we use a multilayer, patch-based approach, rather than operate on entire images. Furthermore, we draw negatives from within the input image itself, rather than from the rest of the dataset. We demonstrate that our framework enables one-sided translation in the unpaired image-to-image translation setting, while improving quality and reducing training time. In addition, our method can even be extended to the training setting where each "domain" is only a single image.},
	urldate = {2025-04-19},
	publisher = {arXiv},
	author = {Park, Taesung and Efros, Alexei A. and Zhang, Richard and Zhu, Jun-Yan},
	year = {2020},
	keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@misc{4k_prevalence,
  author       = {{Plastics Industry Association} and {Consumer Technology Association}},
  title        = {{4K Ultra HDTV household penetration in the United States from 2014 to 2018} [Graph]},
  year         = {2018},
  month        = jun,
  note         = {Accessed: 2025-04-29},
  howpublished = {\url{https://www.statista.com/statistics/736142/4k-ultra-hdtv-us-household-penetration}},
}

@misc{wut_is_variance,
	title = {What {Is} {Variance} in {Statistics}? {Definition}, {Formula}, and {Example}},
	shorttitle = {What {Is} {Variance} in {Statistics}?},
	url = {https://www.investopedia.com/terms/v/variance.asp},
	abstract = {Variance is a measurement of the spread between numbers in a data set. Investors use the variance equation to evaluate a portfolio’s asset allocation.},
	language = {en},
	urldate = {2025-04-17},
	journal = {Investopedia},
}

@misc{intro_color_space_vid,
	title = {Introduction to {Color} {Spaces} in {Video} {\textbar} {Matrox} {Video}},
	url = {https://video.matrox.com/en/media/guides-articles/introduction-color-spaces-video},
	abstract = {This guide aims to explain the representation of color in a video setting while outlining the differences between common color models.},
	language = {en},
	urldate = {2025-04-16},
}

@misc{noauthor_576i_nodate,
	title = {576i},
	url = {https://www.drhdmi.eu/dictionary/576i.html},
	urldate = {2025-04-16},
}

@manual{analog2025adv7182a,
  title        = {{ADV7182A}},
  author       = {{Analog Devices}},
  year         = {2025},
  note         = {Accessed: Apr. 22, 2025},
  url          = {https://www.analog.com/media/en/technical-documentation/data-sheets/ADV7182A.pdf}
}
